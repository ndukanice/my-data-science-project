{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKJSnD5raAbi6UFyyv9E49",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndukanice/my-data-science-project/blob/main/Eze_nduka_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "# Install/Upgrade Hugging Face libraries and fsspec\n",
        "# Adding --upgrade to ensure the latest versions are installed\n",
        "!pip install --upgrade datasets transformers fsspec\n",
        "\n",
        "# Import core libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# Import the datasets library\n",
        "from datasets import load_dataset, load_from_disk\n",
        "import os\n",
        "import shutil # Import shutil for cache clearing\n",
        "from transformers import pipeline\n",
        "\n",
        "# Optional: Clear the datasets cache - uncomment if the above upgrade doesn't work\n",
        "# This will remove downloaded datasets and re-download them on the next run\n",
        "# datasets_cache_dir = os.path.expanduser(\"~/.cache/huggingface/datasets\")\n",
        "# if os.path.exists(datasets_cache_dir):\n",
        "#     print(f\"Clearing datasets cache at: {datasets_cache_dir}\")\n",
        "#     shutil.rmtree(datasets_cache_dir)\n",
        "#     print(\"Cache cleared. Rerun the notebook.\")\n",
        "#     # You might want to exit here after clearing the cache\n",
        "#     # exit()\n",
        "\n",
        "# Initialize dataset variable to None\n",
        "dataset = None\n",
        "\n",
        "# Load dataset directly from Hugging Face using the datasets library\n",
        "# The 'emotion' dataset has splits like 'train', 'validation', 'test'\n",
        "# Specifying a revision ('main' is often the default, but explicit can help)\n",
        "try:\n",
        "    dataset = load_dataset(\"emotion\", split=\"train\", revision=\"main\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error loading dataset with revision 'main': {e}\")\n",
        "    print(\"Trying to load without specifying revision...\")\n",
        "    try:\n",
        "         dataset = load_dataset(\"emotion\", split=\"train\")\n",
        "    except Exception as e_no_rev:\n",
        "        print(f\"Failed to load dataset even without revision: {e_no_rev}\")\n",
        "        print(\"Please check your internet connection and ensure Hugging Face Hub is accessible.\")\n",
        "        # Assign None to dataset to indicate failure\n",
        "        dataset = None\n",
        "\n",
        "\n",
        "# Check if dataset was successfully loaded before proceeding\n",
        "if dataset is not None:\n",
        "    # Convert to pandas DataFrame\n",
        "    df = dataset.to_pandas()\n",
        "\n",
        "    # Show first few rows\n",
        "    print(df.head())\n",
        "\n",
        "    # Plot emotion label distribution\n",
        "    df['label'].value_counts().plot(kind='bar', title='Emotion Labels')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Initialize sentiment analysis pipeline\n",
        "    sentiment = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "    # Run test\n",
        "    print(sentiment(\"Eze is officially unstoppable with this notebook ðŸš€\"))\n",
        "else:\n",
        "    print(\"Dataset could not be loaded. Skipping operations that depend on the dataset.\")\n",
        "    # You can still run code that doesn't depend on the dataset here if needed\n",
        "    # For example, initializing the pipeline might still be possible\n",
        "    try:\n",
        "        sentiment = pipeline(\"sentiment-analysis\")\n",
        "        print(sentiment(\"Eze is officially unstoppable with this notebook ðŸš€\"))\n",
        "    except Exception as e:\n",
        "        print(f\"Could not initialize sentiment pipeline: {e}\")"
      ],
      "metadata": {
        "id": "jtShapJEgJww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot emotion label distribution\n",
        "df['label'].value_counts().plot(kind='bar', title='Emotion Labels')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Stf_8nRUhQIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}